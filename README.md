# ğŸ“œ SafeBench-PQC-Benchmark: Post-Quantum Cryptography-Enhanced AI Robustness Benchmark

**ğŸ” Project Focus:**  
SafeBench-PQC-Benchmark is a **Post-Quantum Cryptography (PQC)-enhanced AI robustness benchmarking framework**. It evaluates AI security against classical adversarial attacks (**FGSM, PGD**) and **Kyber-based post-quantum perturbations**.

---

## **ğŸ“Œ Key Features**
- âœ… **Adversarial AI Security Benchmarking** (FGSM, PGD, PQC perturbations)
- âœ… **Kyber512 Post-Quantum Encryption** to enhance AI security
- âœ… **Integrates Foolbox AI Security Library** for adversarial attacks
- âœ… **Python-based framework for reproducible benchmarking**

---

## **ğŸ“‚ Repository Structure**
```bash
SafeBench-PQC-Benchmark/
â”‚â”€â”€ data/                           # CIFAR-10 dataset (Git LFS)
â”‚â”€â”€ liboqs-python/                   # PQC library for Kyber encryption
â”‚â”€â”€ countermeasures_sim.py           # Timing & fault attack simulations
â”‚â”€â”€ fault_injection_sim.py           # PQC fault attack resilience tests
â”‚â”€â”€ pqc_ai_robustness.py             # AI robustness benchmarking script
â”‚â”€â”€ pqc_benchmark.py                 # Kyber PQC benchmarking for AI models
â”‚â”€â”€ timing_attack_sim.py             # Timing attack simulation on PQC
â”‚â”€â”€ .gitattributes                    # Git LFS tracking for large files
â”‚â”€â”€ README.md                        # Project documentation


## ğŸ”¬ Benchmark Results

| Attack Type            | Baseline Accuracy (%) | PQC-Encrypted Accuracy (%) | Adversarial Accuracy (%) |
|------------------------|---------------------- |--------------------------- |--------------------------|
| No Attack              | 12.59                 | 10.01                      | N/A                      |
| FGSM Attack            | N/A                   | N/A                        | 0.31                     |
| PGD Attack             | N/A                   | N/A                        | 0.00                     |
| Quantum Perturbation   | N/A                   | N/A                        | 8.82                     |

Key Insight: PQC encryption enhances AI model security but introduces a slight accuracy drop.

 How to Run SafeBench-PQC-Benchmark

ğŸ”¹ 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/raviraja1218/SafeBench-PQC-Benchmark.git
cd SafeBench-PQC-Benchmark

ğŸ”¹ 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ”¹ 3ï¸âƒ£ Run AI Robustness Benchmark
python pqc_ai_robustness.py

ğŸ”¹ 4ï¸âƒ£ Run PQC Security Benchmark
python pqc_benchmark.py



